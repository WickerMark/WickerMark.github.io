[
  {
    "objectID": "posts/primes.html",
    "href": "posts/primes.html",
    "title": "Generating the nth Prime Number",
    "section": "",
    "text": "Numpy will be used for the square root function later in the code.\nAn array used to store the prime numbers is created and the first two prime numbers are stored.\nNumber, the variable used to represent the current number to be checked if it is prime, is set to 3. This means that the counter, used to represent how many prime numbers have been found, is set to 2, since 3 is the second prime number.\n\nimport numpy as np\n\nprime_list = [2, 3]\nnumber = 3\ncounter = 2\n\nThe prime number to be generated can be set to anything, but for this example, I have used 1000. This means that the while loop will continue to iterate until the counter is no longer less than 1000.\nThe variable number is first incremented by 2 (to emit all even numbers since these cannot be prime).\nA new variable, called prime, stores a boolean value which states if a number is prime or not. Initially, prime is set to True.\nA for loop is used to check if number is divisible by previous prime numbers.\nThe square root function is used here because if the index of the prime number to be checked is greater than the square root of the number, it is not a factor. If this statement is true, the code breaks out of the for loop.\nHere, I use the modulo operator to determine if the number has a remainder when dividing by previous prime numbers. If it does, the number is determined as a composite number, and so prime is set to False.\nThe final if statement is used such that if the number was determined to be prime, the counter would be incremented, and the number would be appended to the list of prime numbers so that future numbers can be checked against it.\nFinally, counter is cast as a string and concatenated to output the nth prime number.\n\nwhile counter &lt; 1000:\n    number += 2\n    prime = True\n    for i in prime_list:\n        if i &gt; np.sqrt(number):\n            break\n        elif number % i == 0:\n            prime = False\n            break\n    \n    if prime == True:\n        counter += 1\n        prime_list.append(number)\nprint(\"The\", str(counter) + \"th prime number is\", number)\n\nThe 1000th prime number is 7919"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Coding Projects",
    "section": "",
    "text": "Generating the nth Prime Number\n\n\n\n\n\n\nPython\n\n\nPrime Numbers\n\n\n\nPython program which calculates an inputted nth prime number by dividing each consecutive number by previous prime numbers.\n\n\n\n\n\nAug 14, 2024\n\n\nMark\n\n\n\n\n\n\n\n\n\n\n\n\nOptimisation: The Gradient Descent Algorithm for Maching Learning\n\n\n\n\n\n\nPython\n\n\nOptimisation\n\n\nMachine Learning\n\n\n\nPython program which uses the gradient descent algorithm to calculate minimum points for a given function. Used for optimisation in machine learning.\n\n\n\n\n\nAug 13, 2024\n\n\nMark Watson\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About me"
  },
  {
    "objectID": "posts/optimisation.html",
    "href": "posts/optimisation.html",
    "title": "Optimisation: The Gradient Descent Algorithm for Maching Learning",
    "section": "",
    "text": "The objective of this blog post is to create an implementation of a one-dimensional gradient descent algorithm used for optimisation in machine learning where a function needs to be minimised. Shown below is the code and explanations of my implementation of the algorithm.\nFirst, the required libraries are imported and the function f(x) is defined for future use. This can be changed to any function that the user would require. In this example, I have used the equation \\(x\\sin(x)+\\cos(x)+x\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n# Creates the function\ndef f(x):\n    return x * np.sin(x) + (np.cos(x) + x)\n\nThis function calculates the numerical derivative using the small step Ïµ. This is defined by the equation \\(f'(x)\\approx\\frac{f(x + \\epsilon)-f(x - \\epsilon)}{2\\epsilon}\\).\n\n# Function to differentiate\ndef derivative(f, x):\n    eps = 1e-8\n    der = (f(x + eps) - f(x - eps)) / (2 * eps)\n    \n    return der\n\nThe following function performs the gradient descent algorithm. There are two stopping conditions for the algorithm, a maximum number of iterations, and if the absolute value of the gradient is lower than a set threshold value. The variable alpha is the learning rate of the algorithm, a scalar quantity which controls the size of the steps the algorithm takes. The equation \\(\\theta_{t+1}=\\theta_t-\\alpha\\nabla_{\\theta}f(\\theta_t)\\) is used to update the position of the marker until the minimum point is found.\n\n# Function to perform the gradient descent algorithm\ndef descent(f, derivative, xk, alpha=1e-3, tol=1e-4, max_iters=10000):\n    for i in range(max_iters):\n        grad = derivative(f, xk)\n        if abs(grad) &lt; tol:\n            break\n        xk = xk - alpha * grad\n\n    return xk\n\nThe algorithm is then ran from various different starting points until the lowest minima is found. In this example, I uses starting points between -12 and 12.\n\nxk_points = []\nyk_points = []\nfor i in np.arange(-12,12):\n    # Starting position\n    xk = i\n    # Finds the x coordinate of each minima\n    xk = descent(f, derivative, xk)\n    xk_points.append(xk)\n\n    # Finds the y coordinate of the minima for plotting\n    yk = f(xk)\n    yk_points.append(yk)\n\n# Prints the y coordiante of the optimal minimum\nprint(\"The optimal minimum has y coordinate\", min(yk_points))\n\nThe optimal minimum has y coordinate -22.036404343345218\n\n\nThe below code generates the function, its derivative and the minima found by the algorithm.\n\n# Creates an array of x coordinates and finds corresponding y coordinates \n# for plotting\nx = np.linspace(-15, 15, 100)\ny = f(x)\n\n# Differentiates x coordinates to create the graph of the first derivative\ndydx = np.array([derivative(f, xi) for xi in x])\n\n# Plots the curves\nplt.plot(x, y, label=\"f(x)\")\nplt.plot(x, dydx, label=\"f'(x)\")\nplt.scatter(xk_points, yk_points, marker=\"x\", color=\"red\", label=\"Minima\")\n\n# Sets parameters of the plot and plots the curves\nplt.xlim(-15, 15)\nplt.grid()\nplt.legend()\n\nplt.show()"
  }
]